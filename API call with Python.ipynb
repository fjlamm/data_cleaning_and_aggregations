{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping High Charts on Website\n",
    "\n",
    "We have to verify the data showing on a website using high charts. We already checked the data on the database that feeds this chart. But, since there are some calculations done on the API call, we also would like to verify the actual chart to make sure there are no errors on the call.\n",
    "\n",
    "In order to do this, we'll call the api from our python code and store the results, export into a csv file to compare in another script with our actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's begin by testing the api call\n",
    "import requests\n",
    "myUrl = '####'\n",
    "parameters = {'##':'#####','###':'##'}\n",
    "headers = {'##': '##/###, ##/####, */*',\n",
    "        '####': '##, ###, ####',\n",
    "        '####-####': '####'}\n",
    "r = requests.get(url=myUrl,params = parameters, headers=headers)\n",
    "r_data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(r_data[0]['graphData'])\n",
    "results = {}\n",
    "for i in range(0,size):\n",
    "    results[r_data[0]['graphData'][i]['name']]=r_data[0]['graphData'][i]['total']['value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our api call is working. But, we want to store the results for all our locations. So, let's create a dictionary with our locations codes and names, iterate over it, call the api on each element, store the results on our results dictionary based on the location name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's rewrite our code above to store location name and results\n",
    "size = len(r_data[0]['graphData'])\n",
    "location_results = {}\n",
    "results = {}\n",
    "for i in range(0,size):\n",
    "    location_results[r_data[0]['graphData'][i]['name']]=r_data[0]['graphData'][i]['total']['value']\n",
    "results[parameters.get('###')]=location_results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're now ready to bring in the locations data and iterate over it doing our api call and store the results\n",
    "#let's bring in the locations name from an excel file\n",
    "\n",
    "import pandas as pd\n",
    "campuses = pd.read_excel('####.xlsx',sheet_name='####',header=None,names=['####','####'])\n",
    "campuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campus_dict = campuses.set_index('id')['campus'].to_dict()\n",
    "print(campus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now have a dictionary with the location ids and the location names. We can now iterate over it and do the api call for each\n",
    "results = {}\n",
    "for key, value in campus_dict.items():\n",
    "    parameters = {'type':'YearToDateAverages','####':key}\n",
    "    r = requests.get(url=myUrl,params = parameters, headers=headers)\n",
    "    r_data = r.json()\n",
    "    size = len(r_data[0]['graphData'])\n",
    "    location_results = {}\n",
    "    for i in range(0,size):\n",
    "        location_results[r_data[0]['graphData'][i]['name']]=r_data[0]['graphData'][i]['total']['value']\n",
    "    results[value]=location_results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df = pd.DataFrame.from_dict(results,orient='index',columns=['campus','2019','2018','2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df['campus']=api_df.index\n",
    "api_df = api_df.reset_index()\n",
    "api_df = api_df.drop(columns=['index'])\n",
    "api_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing results to xlsx file for further analysis\n",
    "writer = pd.ExcelWriter('api_class101.xlsx',engine='xlsxwriter')\n",
    "api_df.to_excel(writer,sheet_name='class101')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
