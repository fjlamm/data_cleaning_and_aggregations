{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Agregation and cleaning\n",
    "Let's start by comparing the Load tab on excel file to the fact table on the warehouse. If these are equal then we move on to check the calculations tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sq\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '####'\n",
    "database = '####'\n",
    "username = '####'\n",
    "password = '####'\n",
    "driver= '{ODBC Driver 17 for SQL Server}'\n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cnxn:\n",
    "    with cnxn.cursor() as crs:\n",
    "        string = ('select #####')\n",
    "    crs.execute(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df = pd.read_sql(string,con=cnxn)\n",
    "fact_df[['Total','Avg']] = fact_df[['Total','Avg']].round(0).astype('int32')\n",
    "fact_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df = pd.read_excel(io='Totals from Load Tab.xlsx',sheet_name='LoadTotals').drop('Unnamed: 0',axis=1).rename({'weekend_date':'Weeks'}, axis=1)\n",
    "load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = fact_df.merge(load_df[['weekend_year','weekend_month','All Campuses']],left_on=['ServiceYear','ServiceMonth'], right_on=['weekend_year','weekend_month'])\n",
    "compare_df.drop(['weekend_year','weekend_month'],axis=1)\n",
    "compare_df['diff'] = compare_df['Avg'] - compare_df['All Campuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_metrics = compare_df[compare_df['Avg']!=compare_df['All Campuses']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "We can see that the error metrics are very small and due to the rounding up during the load calculations. The error is of 0.001% and is acceptable.\n",
    "\n",
    "Let's now move to observe load vs calculations tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ('select #####')\n",
    "with cnxn:\n",
    "    with cnxn.cursor():\n",
    "        cursor.execute(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_month_avg = pd.read_sql(string,con=cnxn)\n",
    "summary_month_avg.columns = ['Year','Month','Avg','Weeks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_month_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_summary_df = summary_month_avg.merge(load_df[['weekend_year','weekend_month','Weeks','All Campuses']],left_on=['Year','Month'], right_on=['weekend_year','weekend_month'])\n",
    "compare_summary_df.drop(['weekend_year','weekend_month'],axis=1)\n",
    "compare_summary_df['diff'] = compare_summary_df['Avg'] - compare_summary_df['All Campuses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_summary = compare_summary_df[~compare_summary_df['diff'].isin([1,-1])]\n",
    "errors_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('errors in warehouse.xlsx',engine='xlsxwriter')\n",
    "errors_metrics.to_excel(writer,sheet_name='Errors in Metrics')\n",
    "errors_summary.to_excel(writer,sheet_name='Errors Summary Monthly Avg')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "Although the numbers on FactMetrics are correct, the calculations table for monthly averages seem off. This is already taking into account the volunteer numbers of the international campuses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
