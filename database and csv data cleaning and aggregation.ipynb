{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(io = '####.xlsx', sheet_name = 'Load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def campus_metrics(df,campus_list,year):\n",
    "    campus_metrics_dict = {}\n",
    "    for campus in campus_list:\n",
    "        filtered_df = df[(df['campus']==campus)&(df['service_date'].dt.year==year)]\n",
    "        attendance = filtered_df['attendance'].sum()\n",
    "        baptisms = filtered_df['baptisms'].sum()\n",
    "        campus_metrics_dict[campus] = {'attendance':attendance,'baptisms':baptisms}\n",
    "    return campus_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campus_list = df['campus'].value_counts().index.to_list()\n",
    "print(campus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_2018 = campus_metrics(df,campus_list,2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "printer = pp.PrettyPrinter(indent=4)\n",
    "printer.pprint(metrics_2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Unnamed: 10']==7].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unnamed column contains whether the day was a Saturday, Sunday or another day. This is good for my calculations.\n",
    "#let's create a function that assigns specific week of the year to each row and for days other than Sunday, assigns to the week of the following sunday\n",
    "\n",
    "attendance_df = df.copy()\n",
    "attendance_df.rename(columns={'Unnamed: 10':'dow'},inplace=True)\n",
    "attendance_df.drop(labels='timezone',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_WOY(series):\n",
    "    woy = series.dt.week\n",
    "    return woy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_df['woy'] = attendance_df['service_date'].agg(return_WOY)\n",
    "attendance_df[attendance_df['service_date'].dt.month.isin([4,12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_woy(df):\n",
    "    for i in range(o,df.shape[0]):\n",
    "        dow = df.loc[i,'dow']\n",
    "        woy = df.loc[i,'woy']\n",
    "        try:\n",
    "            ndow = df.loc[i-1,'dow']\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Researching CSV calculations Vs Fact Metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year']=df['service_date'].dt.year #adding a year and month column to ease grouping\n",
    "df['Month']=df['service_date'].dt.month\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping by Year\n",
    "df_by_year = df[df['Year'].isin([2017,2018,2019])].groupby(['campus','Year'],as_index=False)[['attendance','baptisms','salvations']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\",1000)\n",
    "df_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing warehouse data into dataframe for faster comparisson\n",
    "Rather than checking manually between the csv and the warehouse, I'll just connect to the warehouse via python sqlalchemy and compare the two dataframes. This will make the work faster for other comparissons as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "server = '####'\n",
    "database = '####'\n",
    "username = '######'\n",
    "password = '######'\n",
    "driver= '{ODBC Driver 17 for SQL Server}'\n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "with cnxn:\n",
    "    with cnxn.cursor() as crs:\n",
    "        string = ('select #####')\n",
    "    crs.execute(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_sql(sql=string,con=cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.rename({3:'attendance','':'baptisms','':'salvations'},axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.columns.values[2] = 'attendance'\n",
    "metrics_df.columns.values[3] = 'baptisms'\n",
    "metrics_df.columns.values[4] = 'salvations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_year = df_by_year[df_by_year['campus']!='El Encuentro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_merged = pd.merge(df_by_year,metrics_df,how='outer',left_on=['campus','Year'],right_on=['CampusName',\"ServiceYear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's clean up this dataframe, add columns with the differences and keep for exporting into excel\n",
    "csv_totals_df = df_by_year.copy().replace(to_replace=['Dana Point Harbor','Manila'],value=['Dana Point','South Manila']).rename(columns={'attendance':'csv_attendance','baptisms':'csv_baptisms','salvations':'csv_salvations'}).fillna(0)\n",
    "metrics_df = metrics_df.rename(columns={'attendance':'metrics_attendance','salvations':'metrics_salvations','baptisms':'metrics_baptisms'}).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.merge(csv_totals_df,metrics_df,left_on=['campus','Year'],right_on=['CampusName','ServiceYear']).drop(axis=1,labels = ['CampusName','ServiceYear'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['diff_attendance'] = results_df['csv_attendance']-results_df['metrics_attendance']\n",
    "results_df['diff_baptisms'] = results_df['csv_baptisms']-results_df['metrics_baptisms']\n",
    "results_df['diff_salvations'] = results_df['csv_salvations']-results_df['metrics_salvations']\n",
    "results_df = results_df[(results_df['diff_attendance']!=0)|(results_df['diff_baptisms']!=0)|(results_df['diff_salvations']!=0)]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion 2\n",
    "- No difference between fact metrics and csv on baptisms and salvations\n",
    "- Most of the differences are on 2019 which could be to the noise added lately to the data as part of tests\n",
    "- Only Corona has some differences in data from  years other than 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_metrics_yearly_total_errors = results_df.copy() #these are the errors df for yearly totals for the Fact Metrics Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting rows per Campus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = df.copy() #copying the dataframe from the original load from csv file\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_campus_rows(df):\n",
    "    result_df = df[df['Year'].isin([2017,2018,2019])].groupby(by=['campus','Year'],as_index=False)['attendance'].count()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_rows_count = count_campus_rows(csv_df).rename(columns={'attendance':'csv_rows'}).replace(to_replace=['Dana Point Harbor','Manila'],value=['Dana Point','South Manila'])\n",
    "csv_rows_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now do this query on the Fact Metrics table on the warehouse\n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "with cnxn:\n",
    "    with cnxn.cursor() as crs:\n",
    "        string = ('####')\n",
    "    crs.execute(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_count_df = pd.read_sql(sql=string,con=cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_rows_count = csv_rows_count[csv_rows_count['campus']!='El Encuentro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_count_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_rows_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_comparisson_metrics_csv = pd.merge(csv_rows_count,metrics_count_df,how='inner',left_on=['campus','Year'],right_on=['CampusName','ServiceYear']).drop(['CampusName','ServiceYear'],axis=1).rename(columns={'':'metrics_rows'})\n",
    "count_comparisson_metrics_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_comparisson_metrics_csv = count_comparisson_metrics_csv[count_comparisson_metrics_csv['metrics_rows']!=count_comparisson_metrics_csv['csv_rows']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_comparisson_metrics_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Calculations Vs CSV\n",
    "\n",
    "I will start by the Monthyly Totals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying df already formatted from before\n",
    "csv_totals = csv_totals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new dataframe from new query \n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()\n",
    "with cnxn:\n",
    "    with cnxn.cursor() as crs:\n",
    "        string = ('#####')\n",
    "    crs.execute(string)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_total_df = pd.read_sql(sql=string,con=cnxn).fillna(0).rename(columns={'TotalAttendance':'summary_attendance','TotalBaptisms':'summary_baptisms','TotalSalvations':'summary_salvations'})\n",
    "monthly_total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging with csv data for comparisson\n",
    "monthly_totals_results = pd.merge(csv_totals,monthly_total_df,left_on=['campus','Year'],right_on=['CampusName','Year']).drop(axis=1,labels=['CampusName'])\n",
    "monthly_totals_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_totals_results['diff_attendance'] = monthly_totals_results['csv_attendance']-monthly_totals_results['summary_attendance']\n",
    "monthly_totals_results['diff_baptisms'] = monthly_totals_results['csv_baptisms']-monthly_totals_results['summary_baptisms']\n",
    "monthly_totals_results['diff_salvations'] = monthly_totals_results['csv_salvations']-monthly_totals_results['summary_salvations']\n",
    "monthly_totals_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyTotal_vs_csv = monthly_totals_results[(monthly_totals_results['diff_attendance']!=0)|(monthly_totals_results['diff_salvations']!=0)|(monthly_totals_results['diff_baptisms']!=0)]\n",
    "monthlyTotal_vs_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Comparing Monthly Averages Calculations Vs CSV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['campus']=='Anaheim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the number of weeks\n",
    "grouped_df = df[df['Year'].isin([2017,2018,2019])].copy()\n",
    "grouped_df = grouped_df.groupby(by=['campus','service_date','Year','Month'],as_index=False)[['attendance']].sum()\n",
    "grouped_df = grouped_df[grouped_df['attendance']!=0]\n",
    "grouped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_totals = grouped_df.groupby(by=['campus','Year','Month'],as_index=False).sum()\n",
    "grouped_totals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['dow'] = grouped_df['service_date'].dt.dayofweek\n",
    "grouped_df\n",
    "grouped_counts = grouped_df[grouped_df['dow']==6].groupby(by=['campus','Year','Month'],as_index=False)['service_date'].nunique()\n",
    "grouped_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_avg = grouped_totals.copy()\n",
    "monthly_avg['month_weeks'] = grouped_counts\n",
    "monthly_avg['month_avg'] = (monthly_avg['attendance']/monthly_avg['month_weeks']).astype('int32').round(0)\n",
    "monthly_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_campuses_monthly_avg = monthly_avg.groupby(by=['Year','Month'],as_index=False).mean()\n",
    "all_campuses_monthly_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporticheck up dataframes into one single excel file to share with team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('metrics Vs csv.xlsx',engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_metrics_yearly_total_errors.to_excel(writer,sheet_name='YearlyTotaldifferences')\n",
    "count_comparisson_metrics_csv.to_excel(writer,sheet_name='RowCountDifferences')\n",
    "monthlyTotal_vs_csv.to_excel(writer,sheet_name='MonthlyTotalCalculationErrors')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
